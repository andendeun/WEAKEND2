import os
import requests
import torch
from torch.utils.data import DataLoader
from dataset import EmotionDataset
from model import EmotionClassifier
from transformers import AutoModel
from tqdm import tqdm
import pandas as pd

# âœ… ì‚¬ìš©í•  Google Drive íŒŒì¼ ëª©ë¡
FILE_IDS = {
    "sample1.xlsx": "1_o7DRLRewzZfnRjKCexu-KNLfTFK8_gX",
    "ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜_0407.xlsx": "<ID_ì¶”ê°€>"
    # í•„ìš” ì‹œ ê³„ì† ì¶”ê°€ ê°€ëŠ¥
}

def download_xlsx_from_drive(file_id, destination_path):
    if not os.path.exists(destination_path):
        print(f"ğŸ“¥ {destination_path} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        os.makedirs(os.path.dirname(destination_path), exist_ok=True)
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        response = requests.get(url, stream=True)
        with open(destination_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=32768):
                if chunk:
                    f.write(chunk)
        print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"âœ… {destination_path} ì´ë¯¸ ì¡´ì¬")

# âœ… í•™ìŠµ ê´€ë ¨ ì„¤ì •
def train(xlsx_filename="sample1.xlsx", model_name="kcbert", label_level="ëŒ€ë¶„ë¥˜", num_epochs=3):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    if model_name == "kcbert":
        pretrained = "beomi/kcbert-base"
    elif model_name == "koelectra":
        pretrained = "monologg/koelectra-base-discriminator"
    elif model_name == "klue":
        pretrained = "klue/roberta-base"
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.")

    if xlsx_filename not in FILE_IDS:
        raise ValueError(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ì…ë‹ˆë‹¤: {xlsx_filename}")

    xlsx_path = f"data/{xlsx_filename}"
    download_xlsx_from_drive(FILE_IDS[xlsx_filename], xlsx_path)

    # âœ… ë°ì´í„° ë¡œë”© ë° ì„ì‹œ csv ì €ì¥
    df = pd.read_excel(xlsx_path, engine="openpyxl")
    temp_path = f"data/_temp_{os.path.splitext(xlsx_filename)[0]}.csv"
    df.to_csv(temp_path, index=False, encoding="utf-8-sig")

    dataset = EmotionDataset(temp_path, levels=[label_level], model_name=model_name)
    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

    base_model = AutoModel.from_pretrained(pretrained)
    model = EmotionClassifier(base_model, hidden_size=768, num_labels=len(dataset.label_mappings[label_level]))
    model.to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)
    model.train()

    for epoch in range(num_epochs):
        total_loss = 0
        for batch in tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"][label_level].to(device)

            optimizer.zero_grad()
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            loss_fn = torch.nn.CrossEntropyLoss()
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"\nğŸ“‰ Epoch {epoch+1}: í‰ê·  Loss = {total_loss / len(dataloader):.4f}\n")

    # ëª¨ë¸ ì €ì¥
    save_path = f"checkpoints/{model_name}_{label_level}/model.pt"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torch.save(model.state_dict(), save_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")

# âœ… ë‹¨ë… ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    train(xlsx_filename="sample1.xlsx", model_name="kcbert", label_level="ëŒ€ë¶„ë¥˜", num_epochs=1)