import os
import torch
import gdown
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

@st.cache_resource
def load_model_and_tokenizer_from_drive(
    file_id: str,
    model_name: str = 'monologg/koelectra-base-discriminator',
    num_labels: int = 8,
    tokenizer_folder_id: str = None
):
    """
    1) Google Driveì—ì„œ fine-tuned .pt ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    2) (ì„ íƒ) Driveì—ì„œ tokenizer íŒŒì¼ í´ë” ë‹¤ìš´ë¡œë“œ
    3) tokenizerì™€ base ëª¨ë¸ ë¡œë“œ (local first, then hub)
    4) fine-tuned weights ë®ì–´ì“°ê¸°
    """
    dest_dir    = "models"
    os.makedirs(dest_dir, exist_ok=True)
    # -- weights --
    pt_path     = os.path.join(dest_dir, "koelectra_emotion.pt")
    if not os.path.exists(pt_path):
        try:
            url = f"https://drive.google.com/uc?id={file_id}"
            with st.spinner("ğŸ“¥ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                gdown.download(url, pt_path, quiet=False)
        except Exception as e:
            st.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    # -- tokenizer files --
    tok_dir = os.path.join(dest_dir, "tokenizer")
    if tokenizer_folder_id and not os.path.exists(tok_dir):
        try:
            # Drive í´ë” ì „ì²´ ë‹¤ìš´ë¡œë“œ
            url = f"https://drive.google.com/drive/folders/{tokenizer_folder_id}"
            with st.spinner("ğŸ“¥ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                gdown.download_folder(url, output=tok_dir)
        except Exception as e:
            st.warning(f"í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, í—ˆë¸Œ ì‹œë„: {e}")
    # -- tokenizer load --
    try:
        if os.path.exists(tok_dir):
            tokenizer = AutoTokenizer.from_pretrained(tok_dir, local_files_only=True)
        else:
            tokenizer = AutoTokenizer.from_pretrained(model_name)
    except Exception as e:
        st.error(f"í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise
    # -- base model load --
    try:
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name, num_labels=num_labels
        )
    except Exception:
        st.warning("í—ˆë¸Œ ì—°ê²° ì‹¤íŒ¨, local only ë¡œë“œ ì‹œë„")
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name, num_labels=num_labels, local_files_only=True
        )
    # -- weights apply --
    try:
        state = torch.load(pt_path, map_location='cpu')
        model.load_state_dict(state)
    except Exception as e:
        st.warning(f"fine-tuned weights ì ìš© ì‹¤íŒ¨: {e}")
    model.eval()
    return model, tokenizer
