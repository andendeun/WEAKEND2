import os
import torch
import gdown
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

@st.cache_resource
def load_model_and_tokenizer_from_drive(
    file_id: str,
    model_name: str = 'monologg/koelectra-base-discriminator',
    num_labels: int = 8
):
    """
    1) Google Driveì—ì„œ fine-tuned .pt ëª¨ë¸ íŒŒì¼ì„ ë‚´ë ¤ë°›ê³ 
    2) HF Hubì—ì„œ AutoTokenizer ë° AutoModelForSequenceClassificationì„ ë¡œë“œ
    3) ë‚´ë ¤ë°›ì€ state_dictë¥¼ modelì— ë®ì–´ì”Œì›€
    Drive ë‹¤ìš´ë¡œë“œë‚˜ í—ˆë¸Œ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ìºì‹œë¥¼ ìš°ì„  ì‹œë„í•©ë‹ˆë‹¤.
    """
    dest_dir  = "models"
    dest_path = os.path.join(dest_dir, "koelectra_emotion.pt")
    os.makedirs(dest_dir, exist_ok=True)

    # 1) Driveì—ì„œ .pt íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
    if not os.path.exists(dest_path):
        try:
            url = f"https://drive.google.com/uc?id={file_id}"
            with st.spinner("ğŸ“¥ ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘â€¦"):
                gdown.download(url, dest_path, quiet=False)
        except Exception as e:
            st.warning(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, í—ˆë¸Œì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {e}")

    # 2) AutoTokenizer ë¡œë“œ
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=False)
    except Exception as e:
        st.warning(f"âš ï¸ í† í¬ë‚˜ì´ì € í—ˆë¸Œ ë¡œë“œ ì‹¤íŒ¨({model_name}), ë¡œì»¬ ìºì‹œ ì‹œë„: {e}")
        tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)

    # 3) AutoModelForSequenceClassification ë¡œë“œ
    try:
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels,
            local_files_only=False
        )
    except Exception as e:
        st.warning(f"âš ï¸ ë² ì´ìŠ¤ ëª¨ë¸ í—ˆë¸Œ ë¡œë“œ ì‹¤íŒ¨({model_name}), ë¡œì»¬ ìºì‹œ ì‹œë„: {e}")
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels,
            local_files_only=True
        )

    # 4) fine-tuned weights ë®ì–´ì“°ê¸°
    if os.path.exists(dest_path):
        try:
            state_dict = torch.load(dest_path, map_location='cpu')
            model.load_state_dict(state_dict)
        except Exception as e:
            st.warning(f"âš ï¸ fineâ€‘tuned weights ì ìš© ì‹¤íŒ¨: {e}")

    model.eval()
    return model, tokenizer
