import os
import torch
import gdown
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

@st.cache_resource
def load_model_and_tokenizer_from_drive(
    file_id: str,
    model_name: str = 'monologg/koelectra-base-discriminator',
    num_labels: int = 8
):
    """
    1) Google Driveì—ì„œ fine-tuned .pt ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ
    2) ë¡œì»¬ì— ì»¤ë°‹ëœ tokenizer í´ë”ì—ì„œ í† í¬ë‚˜ì´ì €ë¥¼ ìš°ì„  ë¡œë“œ, ì‹¤íŒ¨ ì‹œ HF Hub fetch
    3) í—ˆë¸Œì—ì„œ base ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    4) fine-tuned ê°€ì¤‘ì¹˜ ë®ì–´ì”Œìš°ê¸°
    """
    # 1) weights íŒŒì¼
    dest_dir = "models"
    os.makedirs(dest_dir, exist_ok=True)
    weights_path = os.path.join(dest_dir, "koelectra_emotion.pt")
    if not os.path.exists(weights_path):
        url = f"https://drive.google.com/uc?id={file_id}"
        with st.spinner("ğŸ“¥ ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘â€¦"):
            gdown.download(url, weights_path, quiet=False)

    # 2) tokenizer: ë¡œì»¬ ì»¤ë°‹ í´ë” ìš°ì„ , ì—†ìœ¼ë©´ í—ˆë¸Œì—ì„œ
    safe_name = model_name.replace("/", "_")
    tokenizer_dir = os.path.join(dest_dir, "tokenizers", safe_name)
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            tokenizer_dir,
            local_files_only=True
        )
    except Exception:
        tokenizer = AutoTokenizer.from_pretrained(model_name)

    # 3) base ëª¨ë¸ ë¡œë“œ (í—ˆë¸Œ fetch í•„ìš”)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=num_labels
    )

    # 4) fine-tuned weights ì ìš©
    state_dict = torch.load(weights_path, map_location='cpu')
    model.load_state_dict(state_dict)
    model.eval()

    return model, tokenizer