import os
import torch
import gdown
import streamlit as st
from transformers import ElectraForSequenceClassification, ElectraTokenizer

@st.cache_resource
def load_model_and_tokenizer_from_drive(
    file_id: str,
    model_name: str = 'monologg/koelectra-base-discriminator',
    num_labels: int = 8
):
    """
    1) êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ pt íŒŒì¼ì„ ë‚´ë ¤ë°›ê³ 
    2) HF í† í¬ë‚˜ì´ì € ë° ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
    3) pt state_dict ë®ì–´ì“°ê¸°
    ì‹¤íŒ¨ì‹œ ëª¨ë‘ í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œì—ì„œë§Œ ë¶ˆëŸ¬ì˜¤ë„ë¡ í´ë°± ì²˜ë¦¬
    """
    dest_dir  = "models"
    dest_path = os.path.join(dest_dir, "koelectra_emotion.pt")
    os.makedirs(dest_dir, exist_ok=True)

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # 1) Driveì—ì„œ ë‹¤ìš´ë¡œë“œ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    if not os.path.exists(dest_path):
        try:
            url = f"https://drive.google.com/uc?id={file_id}"
            with st.spinner("ğŸ“¥ ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘â€¦"):
                gdown.download(url, dest_path, quiet=False)
        except Exception as e:
            st.warning(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, í—ˆë¸Œì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {e}")

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # 2) í† í¬ë‚˜ì´ì € & ë² ì´ìŠ¤ ëª¨ë¸
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    tokenizer = None
    model     = None
    try:
        tokenizer = ElectraTokenizer.from_pretrained(model_name)
    except Exception as e:
        st.error(f"âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

    try:
        model = ElectraForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels
        )
    except Exception as e:
        st.warning(f"âš ï¸ ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_name}), ë¡œì»¬ íŒŒì¼ë§Œ ì‹œë„í•©ë‹ˆë‹¤: {e}")
        model = ElectraForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels,
            local_files_only=True
        )

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # 3) pt state_dict ë®ì–´ì“°ê¸° (ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ)
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    if os.path.exists(dest_path):
        try:
            state = torch.load(dest_path, map_location='cpu')
            model.load_state_dict(state)
        except Exception as e:
            st.warning(f"âš ï¸ fineâ€‘tuned weights ì ìš© ì‹¤íŒ¨: {e}")

    model.eval()
    return model, tokenizer
