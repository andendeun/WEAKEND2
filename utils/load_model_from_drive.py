import os
import torch
import gdown
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

@st.cache_resource
def load_model_and_tokenizer_from_drive(
    file_id: str,
    model_name: str = 'monologg/koelectra-base-discriminator',
    num_labels: int = 8
):
    """
    1) Google Driveì—ì„œ fine-tuned .pt ëª¨ë¸ íŒŒì¼ì„ ë‚´ë ¤ë°›ê³ 
    2) HF Hubì—ì„œ AutoTokenizer ë° AutoModelForSequenceClassificationì„ ë¡œë“œ
    3) ë‚´ë ¤ë°›ì€ state_dictë¥¼ modelì— ë®ì–´ì”Œì›€
    Drive ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê²½ê³  í›„ í—ˆë¸Œì—ì„œë§Œ ë¡œë“œ
    """
    dest_dir  = "models"
    dest_path = os.path.join(dest_dir, "koelectra_emotion.pt")
    os.makedirs(dest_dir, exist_ok=True)

    # 1) Driveì—ì„œ .pt íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
    if not os.path.exists(dest_path):
        try:
            url = f"https://drive.google.com/uc?id={file_id}"
            with st.spinner("ğŸ“¥ ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘â€¦"):
                gdown.download(url, dest_path, quiet=False)
        except Exception as e:
            st.warning(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, í—ˆë¸Œì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {e}")

    # 2) í† í¬ë‚˜ì´ì € ë¡œë“œ (í—ˆë¸Œ fetch)
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # 3) ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ (í—ˆë¸Œ fetch)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=num_labels
    )

    # 4) fine-tuned weights ë®ì–´ì“°ê¸°
    if os.path.exists(dest_path):
        try:
            state_dict = torch.load(dest_path, map_location='cpu')
            model.load_state_dict(state_dict)
        except Exception as e:
            st.warning(f"âš ï¸ fineâ€‘tuned weights ì ìš© ì‹¤íŒ¨: {e}")

    model.eval()
    return model, tokenizer