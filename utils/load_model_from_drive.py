import os
import torch
import gdown
import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification

@st.cache_resource
def load_model_and_tokenizer_from_drive(file_id, num_labels=42):
    dest_path = "models/kcbert_max.pt"
    os.makedirs("models", exist_ok=True)

    # Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(dest_path):
        url = f"https://drive.google.com/uc?id={file_id}"
        with st.spinner("ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
            gdown.download(url, dest_path, quiet=False)

    # ëª¨ë¸ ë¡œë“œ
    model = BertForSequenceClassification.from_pretrained("monologg/kobert", num_labels=num_labels)
    model.load_state_dict(torch.load(dest_path, map_location=torch.device("cpu")))
    model.eval()

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = BertTokenizer.from_pretrained("monologg/kobert")

    return model, tokenizer
