import os
import pandas as pd
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
import requests
load_dotenv()

# âœ… í™˜ê²½ë³€ìˆ˜ë¡œ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# âœ… Google Drive íŒŒì¼ ID
LOG_FILE_ID = "1num0DWWm10m0_AB468pJubvk3oi0i_xK"
log_path = "logs/emotion_log.csv"
feedback_path = "logs/gpt_feedback_log.csv"

def download_csv_from_drive(file_id, destination_path):
    if not os.path.exists(destination_path):
        print(f"ðŸ“¥ {destination_path} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        os.makedirs(os.path.dirname(destination_path), exist_ok=True)
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        response = requests.get(url, stream=True)
        with open(destination_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=32768):
                if chunk:
                    f.write(chunk)
        print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"âœ… {destination_path} ì´ë¯¸ ì¡´ìž¬")

# âœ… ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
download_csv_from_drive(LOG_FILE_ID, log_path)

# âœ… GPT í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def create_prompt(row):
    return f"""
[1] ì„¸ ëª¨ë¸(KCBERT, KOELECTRA, KLUE)ì˜ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  ë³´ì™„í•´ì¤˜.
â†’ ì„œë¡œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ìžˆëŠ” ê²½ìš° ë” ì‹ ë¢°ë„ ë†’ê³  ë§¥ë½ì— ë§žëŠ” ê°ì •ìœ¼ë¡œ í†µí•©í•´ì¤˜.

ë¬¸ìž¥: "{row['input_text']}"

KCBERT ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KCBERT_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KCBERT_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KCBERT_ì†Œë¶„ë¥˜']}

KOELECTRA ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KOELECTRA_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KOELECTRA_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KOELECTRA_ì†Œë¶„ë¥˜']}

KLUE ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KLUE_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KLUE_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KLUE_ì†Œë¶„ë¥˜']}

ì´ì œ ì•„ëž˜ ì§€ì¹¨ì— ë”°ë¼ ì‘ë‹µì„ ìž‘ì„±í•´ì¤˜:

[Admin Only]
ì„¸ ëª¨ë¸ì˜ ê°ì • ê²°ê³¼ë¥¼ ë¹„êµÂ·ê²€í† í•˜ì—¬ ë” ì ì ˆí•œ ê°ì •ì„ íŒë‹¨í•˜ê³ , 
í•„ìš”ì‹œ ë³´ì™„í•´ì¤˜. ë³´ì™„ëœ ê°ì •ì„ ëŒ€Â·ì¤‘Â·ì†Œ ë¶„ë¥˜ í˜•íƒœë¡œ 
ë‘ê´„ì‹ ê°œì¡°ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸í˜•íƒœë¡œ ì •ë¦¬í•´ì¤˜. ê·¸ë¦¬ê³  í•´ë‹¹í•˜ëŠ” ìœ ì €ì—ê²Œ
í•„ìš”í•œ ëŒ€ì²˜ëŠ” ë¬´ì—‡ì¼ì§€ íŒë‹¨í•´ì„œ ê°„ë‹¨í•˜ê²Œ ê¸°ë¡í•´ì¤˜.
ê·¸ë¦¬ê³  ìœ ì €ì‹ë³„ì½”ë“œì™€ ê°ì •ì´ ê¸°ë¡ëœ ë‚ ì§œ(ìˆ«ìž,ë¡œê·¸)ë„ í¬í•¨í•´ì¤˜(ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•´ì„œ ì •ë¦¬)

[User Only]
ë³´ì™„ëœ ê°ì • ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ëž˜ í•­ëª©ì„ ìž‘ì„±í•´ì¤˜:
1. ê°ì • ìƒíƒœ ìš”ì•½ (í•œ ë¬¸ë‹¨)
2. ê³µê°ì ì´ê³  ë”°ëœ»í•œ ìœ„ë¡œì˜ ë§
3. ì‹¤ì²œ ê°€ëŠ¥í•œ í–‰ë™ ì œì•ˆ

ë‹µë³€ì€ ê³µê°ì ì´ê³  ì í•©í•œ ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•œ ê°€ë…ì„±ìžˆëŠ” 
ë¶€ë“œëŸ¬ìš´ ë¬¸ì²´ë¡œ ìž‘ì„±í•´ì¤˜.
"""

# âœ… GPT ì‘ë‹µ ìš”ì²­ í•¨ìˆ˜
def generate_feedback(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê°ì • ì¼€ì–´ ì „ë¬¸ ì‹¬ë¦¬ ë¶„ì„ê°€ìž…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=1200
    )
    return response.choices[0].message.content.strip()

# âœ… ì‘ë‹µ ë¶„ë¦¬ í•¨ìˆ˜
def split_feedback(response_text):
    admin_note = ""
    user_note = ""
    if "[Admin Only]" in response_text and "[User Only]" in response_text:
        parts = response_text.split("[User Only]")
        admin_note = parts[0].replace("[Admin Only]", "").strip()
        user_note = parts[1].strip()
    else:
        user_note = response_text.strip()
    return admin_note, user_note

# âœ… ì „ì²´ ì‹¤í–‰ìš©
def run_gpt_feedback():
    df = pd.read_csv(log_path)
    latest = df.tail(1).iloc[0]

    prompt = create_prompt(latest)
    print("\nðŸ“¤ GPT ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")

    response_text = generate_feedback(prompt)
    print("\nðŸ“¥ GPT ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ!")

    admin_note, user_note = split_feedback(response_text)

    feedback_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input_text": latest['input_text'],
        "admin_feedback": admin_note,
        "user_feedback": user_note
    }

    if os.path.exists(feedback_path):
        pd.DataFrame([feedback_entry]).to_csv(feedback_path, mode='a', index=False, header=False)
    else:
        pd.DataFrame([feedback_entry]).to_csv(feedback_path, index=False)

    print("\nâœ… GPT ê°ì • í”¼ë“œë°± ì €ìž¥ ì™„ë£Œ!")
    print("\nðŸ“˜ [User ì „ìš© í”¼ë“œë°±]\n")
    print(user_note)
    print("\nðŸ” [Admin ì°¸ê³ ìš© ë¶„ì„]\n")
    print(admin_note)

# âœ… Streamlit ì•±ì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜
def get_gpt_feedback(row: dict) -> str:
    prompt = create_prompt(row)
    response = generate_feedback(prompt)
    _, user_note = split_feedback(response)
    return user_note

if __name__ == "__main__":
    run_gpt_feedback()