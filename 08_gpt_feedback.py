import os
import pandas as pd
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

# âœ… í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ”§ íŒŒì¼ ê²½ë¡œ ì„¤ì •
LOG_PATH = "D:/workspace/Project/logs/emotion_log.csv"
FEEDBACK_PATH = "D:/workspace/Project/logs/gpt_feedback_log.csv"

# âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜

def create_prompt(row):
    return f"""
[1] ì„¸ ëª¨ë¸(KCBERT, KOELECTRA, KLUE)ì˜ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  ë³´ì™„í•´ì¤˜.
â†’ ì„œë¡œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ë” ì‹ ë¢°ë„ ë†’ê³  ë§¥ë½ì— ë§ëŠ” ê°ì •ìœ¼ë¡œ í†µí•©í•´ì¤˜.

ë¬¸ì¥: "{row['input_text']}"

KCBERT ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KCBERT_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KCBERT_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KCBERT_ì†Œë¶„ë¥˜']}

KOELECTRA ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KOELECTRA_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KOELECTRA_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KOELECTRA_ì†Œë¶„ë¥˜']}

KLUE ë¶„ì„ ê²°ê³¼:
  - ëŒ€ë¶„ë¥˜: {row['KLUE_ëŒ€ë¶„ë¥˜']}
  - ì¤‘ë¶„ë¥˜: {row['KLUE_ì¤‘ë¶„ë¥˜']}
  - ì†Œë¶„ë¥˜: {row['KLUE_ì†Œë¶„ë¥˜']}

ì´ì œ ì•„ë˜ ì§€ì¹¨ì— ë”°ë¼ ì‘ë‹µì„ ì‘ì„±í•´ì¤˜:

[Admin Only]
ì„¸ ëª¨ë¸ì˜ ê°ì • ê²°ê³¼ë¥¼ ë¹„êµÂ·ê²€í† í•˜ì—¬ ë” ì ì ˆí•œ ê°ì •ì„ íŒë‹¨í•˜ê³ , 
í•„ìš”ì‹œ ë³´ì™„í•´ì¤˜. ë³´ì™„ëœ ê°ì •ì„ ëŒ€Â·ì¤‘Â·ì†Œ ë¶„ë¥˜ í˜•íƒœë¡œ 
ë‘ê´„ì‹ ê°œì¡°ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸í˜•íƒœë¡œ ì •ë¦¬í•´ì¤˜. ê·¸ë¦¬ê³  í•´ë‹¹í•˜ëŠ” ìœ ì €ì—ê²Œ
í•„ìš”í•œ ëŒ€ì²˜ëŠ” ë¬´ì—‡ì¼ì§€ íŒë‹¨í•´ì„œ ê°„ë‹¨í•˜ê²Œ ê¸°ë¡í•´ì¤˜.
ê·¸ë¦¬ê³  ìœ ì €ì‹ë³„ì½”ë“œì™€ ê°ì •ì´ ê¸°ë¡ëœ ë‚ ì§œ(ìˆ«ì,ë¡œê·¸)ë„ í¬í•¨í•´ì¤˜(ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•´ì„œ ì •ë¦¬)

[User Only]
ë³´ì™„ëœ ê°ì • ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ í•­ëª©ì„ ì‘ì„±í•´ì¤˜:
1. ê°ì • ìƒíƒœ ìš”ì•½ (í•œ ë¬¸ë‹¨)
2. ê³µê°ì ì´ê³  ë”°ëœ»í•œ ìœ„ë¡œì˜ ë§
3. ì‹¤ì²œ ê°€ëŠ¥í•œ í–‰ë™ ì œì•ˆ

ë‹µë³€ì€ ê³µê°ì ì´ê³  ì í•©í•œ ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•œ ê°€ë…ì„±ìˆëŠ” 
ë¶€ë“œëŸ¬ìš´ ë¬¸ì²´ë¡œ ì‘ì„±í•´ì¤˜.
"""

# âœ… GPT ì‘ë‹µ ìš”ì²­ í•¨ìˆ˜
def generate_feedback(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê°ì • ì¼€ì–´ ì „ë¬¸ ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=1200
    )
    return response.choices[0].message.content.strip()

# âœ… ì‘ë‹µ ë¶„ë¦¬ í•¨ìˆ˜
def split_feedback(response_text):
    admin_note = ""
    user_note = ""
    if "[Admin Only]" in response_text and "[User Only]" in response_text:
        parts = response_text.split("[User Only]")
        admin_note = parts[0].replace("[Admin Only]", "").strip()
        user_note = parts[1].strip()
    else:
        user_note = response_text.strip()
    return admin_note, user_note

# âœ… ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜
def run_gpt_feedback():
    df = pd.read_csv(LOG_PATH)
    latest = df.tail(1).iloc[0]

    prompt = create_prompt(latest)
    print("\nğŸ“¤ GPT ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")

    response_text = generate_feedback(prompt)
    print("\nğŸ“¥ GPT ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ!")

    admin_note, user_note = split_feedback(response_text)

    feedback_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input_text": latest['input_text'],
        "admin_feedback": admin_note,
        "user_feedback": user_note
    }

    if os.path.exists(FEEDBACK_PATH):
        pd.DataFrame([feedback_entry]).to_csv(FEEDBACK_PATH, mode='a', index=False, header=False)
    else:
        pd.DataFrame([feedback_entry]).to_csv(FEEDBACK_PATH, index=False)

    print("\nâœ… GPT ê°ì • í”¼ë“œë°± ì €ì¥ ì™„ë£Œ!")
    print("\nğŸ“˜ [User ì „ìš© í”¼ë“œë°±]\n")
    print(user_note)
    print("\nğŸ” [Admin ì°¸ê³ ìš© ë¶„ì„]\n")
    print(admin_note)

if __name__ == "__main__":
    run_gpt_feedback()