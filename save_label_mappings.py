import os
import json
import csv
import pandas as pd
from dataset import get_emotion_name

# âœ… Google Drive ê³µìœ  ë§í¬ â†’ ë‹¤ìš´ë¡œë“œìš© ë§í¬ë¡œ ë³€í™˜
EXCEL_FILE_ID = "1_o7DRLRewzZfnRjKCexu-KNLfTFK8_gX"
EXCEL_URL = f"https://drive.google.com/uc?export=download&id={EXCEL_FILE_ID}"

# âœ… ë§¤í•‘ ì €ì¥ í•¨ìˆ˜
def save_all_label_mappings():
    models = ["kcbert", "koelectra", "klue"]
    levels = ["ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]
    save_dir = "label_mappings"
    os.makedirs(save_dir, exist_ok=True)

    print("ğŸ“‚ ë§¤í•‘ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±:", save_dir)

    # âœ… ì—‘ì…€ íŒŒì¼ ì½ê¸°
    print("ğŸ“¥ Excel ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë”© ì¤‘...")
    df = pd.read_excel(EXCEL_URL)
    print("âœ… Excel ë¡œë”© ì™„ë£Œ")

    for model in models:
        print(f"\nğŸš€ ëª¨ë¸ [{model}]ì˜ ë ˆì´ë¸” ë§¤í•‘ ìƒì„± ì¤‘...")
        for level in levels:
            if level not in df.columns:
                print(f"âš ï¸ {level} ì»¬ëŸ¼ ì—†ìŒ - ìŠ¤í‚µ")
                continue

            unique_values = df[level].dropna().unique().tolist()

            mapping = {}
            for idx, raw_label in enumerate(unique_values):
                key = f"{level}{idx + 1}"
                corrected_label = get_emotion_name(level, raw_label)
                mapping[key] = {"label": corrected_label, "index": idx}

            save_path = os.path.join(save_dir, f"{model}_{level}_mapping.json")
            with open(save_path, "w", encoding="utf-8") as f:
                json.dump(mapping, f, ensure_ascii=False, indent=2)
            print(f"  âœ… {model}_{level}_mapping.json ì €ì¥ ì™„ë£Œ")

    print("\nğŸ‰ ì „ì²´ ë ˆì´ë¸” ë§¤í•‘ ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    save_all_label_mappings()
